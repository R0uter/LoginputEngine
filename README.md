# 落格拼音整句引擎

落格输入法 X 和 落格输入法 macOS 2 中使用的整句拼音算法引擎。
现在起开源了，希望能和大家一起学习成长。

---

## 简介

该引擎使用 Python 实现，包含了模型生成工具和整句计算样例算法，
使用 LMDB 存储转移数据，使用 SQLite 存储拼音数据，支持全拼、简拼以及全拼和简拼的混合拼音。

对于 `fangan` 这类拼音，引擎不进行处理，目前该引擎不包含拼音拆分算法，
但对于 `xian`、`qie`、`jian` 这类既能按一个拼音处理（如"先"、"且"、"键"），也能按两个拼音拆分的（如"西安"、"企鹅"、"吉安"），
引擎在模型生成之初就进行了兼容，我在统计最初就额外进行了处理，具体见训练部分相关代码注释。

由于拼音查询使用 SQLite，所以引擎天生支持模糊音，`fangan` 这一类拼音也可以根据需要由开发者自行处理（其实常见的没几个）

## 算法模型

该引擎使用隐马尔科夫模型和统计语言模型混搭概念实现，3-Gram（Tri-Gram）转移矩阵，使用 DAG（动态规划）进行求解。
Gram 单位为"词汇"，这样大大降低了算法遍历次数（相对于以字为单位来说），平滑使用简单的最大似然法处理，转移不存在则退回低阶，都不存在则使用一阶最小值。
训练时使用 `fast jieba` 进行分词，并用 `OpenCC` 统一转换为简体字处理。
考虑到中文输入时大多数情况下并不是从一句话开头进行打字，训练时不对语句进行起止标记。

## 数据结构

引擎需要两个数据文件进行计算，一个是 拼音->字词 的数据库（发射），另一个是 字词之间转移（转移） 的数据库。

### 发射数据库

发射数据库使用 SQLite ，好处是无需额外做前缀查询等处理，直接使用 SQL 语句即可，坏处是查询速度可能相对较慢，
对此我对 SQLite 进行了一系列参数优化，目前性能不错，也希望各位能提供更好的思路和算法。

为了加速模糊音和简拼处理，这里我对拼音进行了特殊的编码处理，使其用一个整数进行表达，并可进行声母和韵母（严格来讲是除了声母的部分）拆分合并。

为了加快 SQLite 查询，除了参数优化外，数据结构也是重点，首先，我根据词汇字数创建表，从 1 个字`w1`，一直到 8 个字`w8`（目前限制最大 8 字词）。
其次，每个拼音为一个字段，比如`w3`表:
```sql
CREATE TABLE "w3" (
	"p1"	INTEGER,
	"p2"	INTEGER,
	"p3"	INTEGER,
	"Words"	BLOB
);
```
如你所见，words 字段只有一个，它合并了所有这个拼音下可能出现的词汇，并按照 Uni-Gram 转移进行排序，比如：`你_泥_匿_铌` 类似这样。
_排序是为了方便单独查询，其实不排也就那样……_

总之，为了后续能方便和 LMDB 兼容以及文件体积考虑，`Words` 字段使用 `GB18030` 进行二进制编码，该编码对中文为两个字节，缩小体积，
另外 Python 对文本编码处理速度~~蜜汁~~极快，所以无需担心这方面问题。

> 注意，如果使用其他编程语言实现该算法，应当注意这个问题，比如落格输入法用 Swift 实现查询算法后，速度比 Python 版本慢一倍，
>究其原因，就是 String 与二进制文本编码转换太慢，最终我选择了直接操作二进制……

### 转移数据库

转移数据库使用 LMDB，写入速度一般，但读取的速度是极快的，将词汇转移以 `你好_我是_落格输入法` 这样的格式平铺存储，
由于 LMDB 要求存入二进制数据，所以 Key 同样使用 `GB18030` 编码处理，大大缩小了中文的存储体积， Value 则是 `Double` 类型的二进制文件。


